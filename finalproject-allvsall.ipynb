{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Template \n",
    " \n",
    "This template use principal component analysis and Bayesian classifier for classifier design and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# revision for output files\n",
    "rev = \"r10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output results directory\n",
    "rDir = \"results\"\n",
    "\n",
    "# Output plots direcotry\n",
    "pDir = \"plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1    \n",
    "The handwritten digit data from \n",
    "https://github.com/davidflanagan/notMNIST-to-MNIST (four files) was imported and stored in the **`data`** subdirectory. You need both the training and testing data for this template. The Python code suggested in [Read_MNIST.html](https://ucsc-extension.instructure.com/courses/784/files/95974/download?wrap=1) was modified to read and parse the data in this data set by changing the input file names.\n",
    "\n",
    "* A copy of the training and test data are stored in the **`data`** subdirectory.\n",
    "* The output plots are stored in the **`plots`** subdirectory.\n",
    "* Some classification results are stored as CSV files in the **`results`** subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import matplotlib as plt\n",
    "from array import array as pyarray\n",
    "import numpy as np\n",
    "import time\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(dataset=\"training\", digits=range(10), path='./data'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Adapted from: http://cvxopt.org/applications/svm/index.html?highlight=mnist\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = np.zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = np.zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "Prepare the data that will use for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert between digit and letter\n",
    "digit2letter = pd.Series(list(\"ABCDEFGHIJ\"))\n",
    "letter2digit = {digit2letter[d] : d for d in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A\n",
      "1    B\n",
      "2    C\n",
      "3    D\n",
      "4    E\n",
      "5    F\n",
      "6    G\n",
      "7    H\n",
      "8    I\n",
      "9    J\n",
      "dtype: object\n",
      "{'A': 0, 'C': 2, 'B': 1, 'E': 4, 'D': 3, 'G': 6, 'F': 5, 'I': 8, 'H': 7, 'J': 9}\n"
     ]
    }
   ],
   "source": [
    "print digit2letter\n",
    "print letter2digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use all letters\n",
    "digits = np.array(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters = digit2letter[digits].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "<type 'numpy.ndarray'>\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J']\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print digits\n",
    "print type(digits)\n",
    "print letters\n",
    "print type(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels = load_mnist('training', digits=digits)\n",
    "images_test, labels_test = load_mnist('testing', digits=digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3   \n",
    "Prepare the X matrix and target vector T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def select_random_samples(X, T, num_samples = 16, rseed=0):\n",
    "#    if rseed != None :\n",
    "#        np.random.seed(rseed)\n",
    "#    idx = np.random.choice(T.shape[0],size=num_samples)\n",
    "#    XList = X[idx]\n",
    "#    TList = T[idx]\n",
    "#    return XList, TList\n",
    "#\n",
    "#def plot_samples(XList, TList, width=28, ncol=4, fName= None):\n",
    "#    fig = plt.figure()\n",
    "#    num_samples = XList.shape[0]\n",
    "#    for n, x  in enumerate(XList) :\n",
    "#        sample = x.reshape(width, width)\n",
    "#        plt.subplot((num_samples+ncol-1)/ncol, ncol, n+1)\n",
    "#        plt.imshow(sample, interpolation='None', cmap='gray')\n",
    "#        plt.title(\"{}\".format(TList[n]))\n",
    "#        plt.xticks([])\n",
    "#        plt.yticks([])\n",
    "#    plt.tight_layout(pad=1, w_pad=0.2, h_pad=0.2)\n",
    "#    fig.set_size_inches(6,6)\n",
    "#    if fName != None:\n",
    "#        savefig(fName, bbox_inches='tight')\n",
    "#    plt.show()\n",
    "#\n",
    "#def plot_random_samples(X, T, width=28, num_samples = 16, ncol=4, rseed=0, fName=None):\n",
    "#    XList, TList = select_random_samples(X,T,16, rseed)\n",
    "#    plot_samples(XList, TList, width, ncol, fName)\n",
    "#\n",
    "#def plot_sample(x,title=\"\",width=28,fName=None) :\n",
    "#    fig = plt.figure()\n",
    "#    sample = x.reshape(width, width)\n",
    "#    # interploation can be 'nearest' to put grid at the center the pixels\n",
    "#    plt.imshow(sample, interpolation='None', cmap='gray')\n",
    "#    plt.title(title)\n",
    "#    plt.xticks([])\n",
    "#    plt.yticks([])\n",
    "#    if fName != None:\n",
    "#        savefig(fName, bbox_inches='tight')\n",
    "#    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting from NX28X28 array into NX784 array\n",
    "def reformatSamples(images,labels) :\n",
    "    flatimages = list()\n",
    "    for i in images:\n",
    "        flatimages.append(i.ravel())\n",
    "    X = np.asarray(flatimages)\n",
    "    T = labels.reshape(-1)\n",
    "    return X, T\n",
    "\n",
    "def convertDigitsToLetters(T,digit2letter) :\n",
    "    L = np.array([digit2letter[d] for d in T])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, T = reformatSamples(images,labels)\n",
    "L = convertDigitsToLetters(T,digit2letter)\n",
    "\n",
    "X_test, T_test =  reformatSamples(images_test,labels_test)\n",
    "L_test = convertDigitsToLetters(T_test,digit2letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix     :  (60000, 784)\n",
      "Shape of labels     :  (60000,)\n",
      "Unique Lables       :  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
      "Mins and Max Values :  (0, 255)\n"
     ]
    }
   ],
   "source": [
    "print \"Shape of matrix     : \", X.shape\n",
    "print \"Shape of labels     : \", T.shape\n",
    "print \"Unique Lables       : \", tuple(set(T))\n",
    "print \"Mins and Max Values : \", (np.amin(X),np.amax(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test matrix     :  (10000, 784)\n",
      "Shape of test labels     :  (10000,)\n",
      "Unique test Lables       :  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
      "Mins and Max test Values :  (0, 255)\n"
     ]
    }
   ],
   "source": [
    "print \"Shape of test matrix     : \", X_test.shape\n",
    "print \"Shape of test labels     : \", T_test.shape\n",
    "print \"Unique test Lables       : \", tuple(set(T_test))\n",
    "print \"Mins and Max test Values : \", (np.amin(X_test),np.amax(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check training vector by plotting image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fName = os.path.join(pDir,\"samples_of_X_{}.png\".format(rev))\n",
    "#XList, TList = select_random_samples(X,L,16)\n",
    "#plot_samples(XList, TList, fName = fName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4   \n",
    "Go through the XZCVP procedure to produce P which is the 2D approximation to X. Produce a 2D scatterplot showing the two classes. Plot the mean vector `mu` and 16 eigenvectors calculated in completing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPCA(X) :\n",
    "    C = np.cov(X,rowvar=False)\n",
    "    w, U = np.linalg.eigh(C)\n",
    "    \n",
    "    # reorder the eigenvector and eigenvector in decreasing order of eigenvalue\n",
    "    V = U[:,::-1] # eigenvector\n",
    "    s = w[::-1]   # eigenvalue\n",
    "    return C, V, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C, V, s = getPCA(X)\n",
    "mu = np.mean(X,axis=0)\n",
    "Z = X - mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mu : (784,)\n",
      "max of mu   : 172.874566667\n",
      "min of mu   : 38.62675\n"
     ]
    }
   ],
   "source": [
    "print \"shape of mu :\", mu.shape\n",
    "print \"max of mu   :\", mu.max()\n",
    "print \"min of mu   :\", mu.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Z  : (60000, 784)\n",
      "max of Z    : 216.37325\n",
      "min of Z    : -172.874566667\n",
      "max of mean(Z) : 7.99196205511e-13\n",
      "min of mean(Z) : -8.80027073435e-13\n"
     ]
    }
   ],
   "source": [
    "print \"shape of Z  :\", Z.shape\n",
    "print \"max of Z    :\", Z.max()\n",
    "print \"min of Z    :\", Z.min()\n",
    "print \"max of mean(Z) :\", Z.mean(axis=0).max()\n",
    "print \"min of mean(Z) :\", Z.mean(axis=0).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fName = os.path.join(pDir,\"mean_of_X_{}.png\".format(rev))\n",
    "#plot_sample(mu,\"means of all letters \",fName=fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.plot(range(len(mu)),mu)\n",
    "#plt.ylim([0,180])\n",
    "#plt.xlim([0,800])\n",
    "#fig.set_size_inches(8,8)\n",
    "#fName = os.path.join(pDir,'mean_{}.png'.format(rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fName = os.path.join(pDir,\"samples_of_Z_{}.png\".format(rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plot_random_samples(Z,L,fName=fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.imshow(C, interpolation='None', cmap=cm.gray)\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(\"Covariance Matrix\")\n",
    "#fig.set_size_inches(8,8)\n",
    "#fName = os.path.join(pDir,'cov_{}.png'.format(rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.plot(range(len(s)),s)\n",
    "#plt.title(\"Eigen Value\")\n",
    "#plt.grid(\"on\")\n",
    "#fig.set_size_inches(8,8)\n",
    "#fName = os.path.join(pDir,'eigen_value_{}.png'.format(rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.plot(range(len(s)),s.cumsum()/s.sum())\n",
    "#plt.title(\"Normalized Cumulative Sum of Eigen Value\")\n",
    "#plt.ylim([0,1.2])\n",
    "#plt.grid(\"on\")\n",
    "#fig.set_size_inches(8,8)\n",
    "#fName = os.path.join(pDir,'eigen_value_cum_sum_{}.png'.format(rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of (V*V.T - I) : 7.30788698066e-14\n",
      "Max of (V.T*V - I)     : 3.10862446895e-15\n",
      "Min of (V.T*V - I)     : -2.59514632006e-15\n",
      "L2 norm of (V*V.T - I) : 7.30788698066e-14\n",
      "Max of (V.T*V - I)     : 3.10862446895e-15\n",
      "Min of (V.T*V - I)     : -2.59514632006e-15\n"
     ]
    }
   ],
   "source": [
    "print \"L2 norm of (V*V.T - I) :\", np.linalg.norm(np.dot(V,V.T) - np.identity(V.shape[0]))\n",
    "print \"Max of (V.T*V - I)     :\", np.max(np.dot(V.T,V) - np.identity(V.shape[0]))\n",
    "print \"Min of (V.T*V - I)     :\", np.min(np.dot(V.T,V) - np.identity(V.shape[0]))\n",
    "print \"L2 norm of (V*V.T - I) :\", np.linalg.norm(np.dot(V,V.T) - np.identity(V.shape[0]))\n",
    "print \"Max of (V.T*V - I)     :\", np.max(np.dot(V.T,V) - np.identity(V.shape[0]))\n",
    "print \"Min of (V.T*V - I)     :\", np.min(np.dot(V.T,V) - np.identity(V.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of (V*S*V.T - C) : 7.54188124494e-09\n",
      "Max of (V*S*V.T - C)     : 1.09139364213e-10\n",
      "Min of (V*S*V.T - C)     : -2.34649633057e-10\n"
     ]
    }
   ],
   "source": [
    "C2 = np.dot(V,np.dot(np.diag(s),V.T))\n",
    "print \"L2 norm of (V*S*V.T - C) :\", np.linalg.norm(C-C2)\n",
    "print \"Max of (V*S*V.T - C)     :\", np.max(C-C2)\n",
    "print \"Min of (V*S*V.T - C)     :\", np.min(C-C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first 16 principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#m= 16\n",
    "#tittles = [\"PC {}\".format(x+1) for x in range(m)]\n",
    "#fName = os.path.join(pDir,'samples_of_pc_{}.png'.format(rev))\n",
    "#plot_samples(V.T[:m], tittles, width=28, ncol=4, fName=fName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `n` principle components for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "\n",
    "P = np.dot(Z,V[:,:n])\n",
    "R = np.dot(P,V[:,:n].T)\n",
    "RX = R + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.plot(range(n),P.max(axis=0),label=\"max\")\n",
    "#plt.plot(range(n),P.min(axis=0),label=\"min\")\n",
    "#plt.plot(range(n),P.mean(axis=0),label=\"mean\")\n",
    "#plt.plot(range(n),P.std(axis=0),label=\"std\")\n",
    "#plt.ylabel(\"Value of Principle Component\")\n",
    "#plt.xlabel(\"Index of Principle Component\")\n",
    "#plt.legend()\n",
    "#fig.set_size_inches(8,8)\n",
    "#fName = os.path.join(pDir,'describe_PC_n{}_{}.png'.format(n,rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2970.94607214\n",
      "-3852.0903665\n",
      "(60000, 50)\n"
     ]
    }
   ],
   "source": [
    "print P.max()\n",
    "print P.min()\n",
    "print P.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display scatter plot of a list of letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D']\n",
      "ABCD\n"
     ]
    }
   ],
   "source": [
    "a = list(\"ABCD\")\n",
    "print a\n",
    "print \"\".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def scatter_plot(P,L,pcIdx1,pcIdx2,letterList,rev) :\n",
    "#    fig = plt.figure()\n",
    "#    # following the convention in lecture note ScatterPlot.html\n",
    "#    colors = [\"r\",\"lime\",\"b\",\"y\",\"c\",\"m\",\"k\",\"tan\",\"pink\",\"darkred\"]\n",
    "#    for i, letter in enumerate(letterList) :\n",
    "#        plt.scatter(P[L==letter,pcIdx2],P[L==letter,pcIdx1],s=0.1,c=colors[i],label=letter)\n",
    "#    plt.axes().set_aspect('equal')\n",
    "#    #plt.axes().set_aspect('equal', 'datalim')\n",
    "#    plt.xlabel(\"Principle Component {}\".format(pcIdx2))\n",
    "#    plt.ylabel(\"Principle Component {}\".format(pcIdx1))\n",
    "#    plt.axhline(0, color='grey')\n",
    "#    plt.axvline(0, color='grey')\n",
    "#    plt.ylim([-5000,5000])\n",
    "#    plt.xlim([-5000,5000])\n",
    "#    plt.legend()\n",
    "#    plt.gca().invert_yaxis()\n",
    "#    fig.set_size_inches(8,8)\n",
    "#    fName = os.path.join(pDir,'scatter_PC{}_PC{}_{}_{}.png'.format(pcIdx1,pcIdx2,\"\".join(letterList),rev))\n",
    "#    savefig(fName, bbox_inches='tight')    \n",
    "#    plt.show()\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_plot(P,L,0,1,[\"A\",\"B\",\"C\", \"D\"],rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_plot(P,L,2,3,[\"A\",\"B\",\"C\",\"D\"],rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_plot(P,L,4,5,[\"A\",\"B\",\"C\",\"D\"],rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_plot(P,L,6,7,[\"A\",\"B\",\"C\",\"D\"],rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_plot(P,L,8,9,[\"A\",\"B\",\"C\",\"D\"],rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_plot(P,L,n-2,n-1,[\"A\",\"B\",\"C\",\"D\"],rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5    \n",
    "Visually verify that the corresponding element of P, when projected back to 784 dimensions and visualized as an image still looks like the original image. That is, visually verify that reduction in dimension does not significantly compromise the identity of the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fName = os.path.join(pDir,\"samples_of_RX_n{}_{}.png\".format(n,rev))\n",
    "#plot_random_samples(RX,L,fName=fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_random_samples(X,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6    \n",
    "Build a Bayesian classifier assuming that the feature vectors are distributed normally in the reduced dimensional space.  In order to use the  classifier on a 784D query, the mean vectors and eigenvectors (Step 4 above) are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Bayesian\n",
    "Build a $n$-D Bayesian classifier assuming that the feature vectors are distributed normally in the reduced dimensional space. \n",
    " \n",
    "\n",
    "#### Number of samples in each letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = P.shape[0]\n",
    "NList = np.array([P[T==x].shape[0] for x in digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NList = [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n",
      "N     = 60000\n"
     ]
    }
   ],
   "source": [
    "print \"NList =\", NList\n",
    "print \"N     =\", N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of the principle components of each letter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "muList = np.array([P[T==x].mean(axis=0) for x in digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "print muList.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#plt.plot(muList.T)\n",
    "#plt.title(\"Mean of Principle Component\")\n",
    "#plt.xlabel(\"Index of Principle Component\")\n",
    "#plt.axhline(0, color='grey')\n",
    "#plt.legend(letters,loc='upper right')\n",
    "#fig.set_size_inches(8,8)\n",
    "#fName = os.path.join(pDir,'mean_of_pc_n{}_{}.png'.format(n,rev))\n",
    "#savefig(fName, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance matrix of the principle component of each letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covList = np.array([np.cov(P[T==x],rowvar=False) for x in digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "print covList.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7   \n",
    "Run P through the classifiers and record the results (e.g. what is X recognized as? With what probability? \n",
    "\n",
    "### Functions for classification\n",
    "\n",
    "#### A function to get the classification `xc` and probability `xc_p` of a sample `p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bays_classifier(p,NList,muList,covList,classList) :\n",
    "    xH = np.array([NList[x]*multivariate_normal.pdf(p, mean=muList[x], cov=covList[x]) for x in range(NList.shape[0])])\n",
    "    xc = np.argmax(xH)\n",
    "    xc_p = xH[xc]/xH.sum()\n",
    "    xc = classList[xc]\n",
    "    return xc, xc_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function to get the classifications `cb` as digits and the probability `cbp` of all samples in `P`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes_classify(P,NList,muList,covList,digits) :\n",
    "    cb = []  # classfied as indexes\n",
    "    cbp = [] # probability\n",
    "    for i, p in enumerate(P) :\n",
    "        x_cb, x_cb_p = bays_classifier(p,NList,muList,covList,digits)\n",
    "        cb.append(x_cb)\n",
    "        cbp.append(x_cb_p)\n",
    "        #if (i%1000 == 0) : sys.stdout.write('.'),\n",
    "    #print\n",
    "    cb = np.array(cb)\n",
    "    cbp = np.array(cbp)\n",
    "    return cb, cbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 F\n"
     ]
    }
   ],
   "source": [
    "# print bays_classifier(P[0],NList,muList,covList,digits)\n",
    "print T[0], L[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for confusion matrix and related information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCount(groundTruth,gClass,predicted,pClass) :\n",
    "    return np.sum(np.logical_and(groundTruth == gClass, predicted == pClass))\n",
    "  \n",
    "def getTP(groundTruth,predicted,pClass) :\n",
    "    return np.sum(np.logical_and(groundTruth == pClass, predicted == pClass))\n",
    "\n",
    "def getTN(groundTruth,predicted,pClass) :\n",
    "    return np.sum(np.logical_and(groundTruth != pClass, predicted != pClass))\n",
    "   \n",
    "def getFP(groundTruth,predicted,pClass) :\n",
    "    return np.sum(np.logical_and(groundTruth != pClass, predicted == pClass))\n",
    "\n",
    "def getFN(groundTruth,predicted,pClass) :\n",
    "    return np.sum(np.logical_and(groundTruth == pClass, predicted != pClass))\n",
    "\n",
    "def get_acc(groundTruth,predicted) :\n",
    "    return np.sum(groundTruth == predicted)/float(predicted.shape[0])\n",
    "\n",
    "def get_CM2(groundTruth,predicted,pClass) :\n",
    "    TP = getTP(groundTruth,predicted,pClass)\n",
    "    TN = getTN(groundTruth,predicted,pClass)\n",
    "    FP = getFP(groundTruth,predicted,pClass)\n",
    "    FN = getFN(groundTruth,predicted,pClass)\n",
    "    return np.array([[TP, FN], [FP, TN]])\n",
    "\n",
    "def get_sensitivity(TP, FN, FP, TN) :\n",
    "    return TP / float(TP + FN)\n",
    "    \n",
    "def get_specificity(TP, FN, FP, TN) :\n",
    "    return TN / float(FP+TN)\n",
    "    \n",
    "def get_ppv(TP, FN, FP, TN) :\n",
    "    return TP / float(TP+FP)    \n",
    "    \n",
    "def get_accuracy(TP, FN, FP, TN) :\n",
    "    return (TP + TN) / float(TP + FN + FP + TN)   \n",
    "\n",
    "def get_CM(groundTruth,predicted,classList) :\n",
    "    CM = np.zeros((len(classList),len(classList)))\n",
    "    for i, t in enumerate(classList) :\n",
    "        for j, p in enumerate(classList) : \n",
    "          CM[i,j] =  np.sum(np.logical_and(groundTruth == t, predicted == p))  \n",
    "    CM = pd.DataFrame(CM)\n",
    "    CM.columns = classList\n",
    "    CM.index = classList\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify the training and test set with `n` principle components\n",
    "It is not very fast. Please wait.\n",
    " \n",
    "The eigenvectors `V` and the mean vector `mu` were previously computed by\n",
    "```\n",
    "C, V, s = getPCA(X)\n",
    "mu = np.mean(X,axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_bayes(X_train,T_train,X_test,T_test,digits,V,mu,n):\n",
    "    \n",
    "     \n",
    "    #print \"Training Classifier with {} PC\".format(n)\n",
    "    Z = X_train - mu\n",
    "    P = np.dot(Z,V[:,:n])\n",
    "    muList = np.array([P[T_train==x].mean(axis=0) for x in digits])\n",
    "    covList = np.array([np.cov(P[T_train==x],rowvar=False) for x in digits])\n",
    "    #print \"muList\", muList\n",
    "    #print \"covList\", covList\n",
    "    NList = np.array([P[T_train==x].shape[0] for x in digits])\n",
    "    #print \"NNList\", covList\n",
    "    \n",
    "    cb, cbp = bayes_classify(P,NList,muList,covList,digits)\n",
    "     \n",
    "    #print \"Testing  Classifier with {} PC\".format(n)\n",
    "    Z_test = X_test - mu\n",
    "    P_test = np.dot(Z_test,V[:,:n])\n",
    "    cb_test, cbp_test = bayes_classify(P_test,NList,muList,covList,digits)\n",
    "    \n",
    "    return cb, cb_test\n",
    "\n",
    "def map_kesler(T,digits) :\n",
    "    Tk = (T.reshape(-1,1) == digits).astype(int) * 2 -1\n",
    "    return np.array(Tk)\n",
    "    \n",
    "def augment(X) :\n",
    "    Xa = np.insert(X,0,1,axis=1)\n",
    "    return Xa\n",
    "    \n",
    "def train_linear_classifier(Xa,T) :\n",
    "    Xa_pinv = np.linalg.pinv(Xa)\n",
    "    Wt = np.dot(Xa_pinv,T)\n",
    "    return Wt\n",
    "\n",
    "def linear_classify(Xa,Wt,digits) :\n",
    "    T_pred =  np.dot(Xa,Wt)\n",
    "    Xc =  np.argmax(T_pred, axis=1)\n",
    "    return(digits[Xc])\n",
    "    \n",
    "def train_and_test_linear(X_train,T_train,X_test,T_test,digits,V,mu,n):\n",
    "    #print \"Training Classifier with {} PC\".format(n)h\n",
    "    Z = X_train - mu\n",
    "    P = np.dot(Z,V[:,:n])\n",
    "\n",
    "    Tk = map_kesler(T_train,digits)\n",
    "    \n",
    "    Xa = augment(P)\n",
    "    Wt = train_linear_classifier(Xa,Tk)\n",
    "    T_pred = linear_classify(Xa,Wt,digits)\n",
    "     \n",
    "    #print \"Testing  Classifier with {} PC\".format(n)\n",
    "    Z_test = X_test - mu\n",
    "    P_test = np.dot(Z_test,V[:,:n])\n",
    "\n",
    "    Xa_test = augment(P_test)\n",
    "    T_pred_test = linear_classify(Xa_test,Wt,digits)\n",
    "    \n",
    "    return T_pred, T_pred_test\n",
    "    \n",
    "def train_and_test_onevsall(X_train,T_train,X_test,T_test,digits,n, model=0):\n",
    "    if (model == 0):\n",
    "        cb_onevsall, cb_test_onevsall = train_and_test_bayes(X_train,T_train,X_test,T_test,digits,V,mu,n)\n",
    "    if (model == 1):\n",
    "        cb_onevsall, cb_test_onevsall = train_and_test_linear(X_train,T_train,X_test,T_test,digits,V,mu,n)\n",
    "    return cb_onevsall, cb_test_onevsall\n",
    "   \n",
    "def train_and_test_allvsall(X_train,T_train,X_test,T_test,digits,n, model=0):\n",
    "    cb_allvsall = T_train\n",
    "    cb_test_allvsall = T_test\n",
    "    cb_test_allvsall_arr = np.array([]) #np.zeros((digits_comb,T_test.shape[0]))\n",
    "    k = 0\n",
    "    for i in range(digits.shape[0]):\n",
    "        for j in range(digits.shape[0]):\n",
    "            if (j>i):\n",
    "                #print \"Iter is \", k , \"pc is \", n\n",
    "                X_train_allvsall_i = X_train[:, :][T_train[:] == i]\n",
    "                X_train_allvsall_j = X_train[:, :][T_train[:] == j]\n",
    "                T_train_allvsall_i = T_train[:][T_train[:] == i]\n",
    "                T_train_allvsall_j = T_train[:][T_train[:] == j]\n",
    "                X_train_allvsall = np.concatenate([X_train_allvsall_i,X_train_allvsall_j])\n",
    "                T_train_allvsall = np.concatenate([T_train_allvsall_i,T_train_allvsall_j])\n",
    "                digits_allvsall = np.zeros(2)\n",
    "                digits_allvsall[0]=i\n",
    "                digits_allvsall[1]=j\n",
    "                C_allvsall, V_allvsall, s_allvsall = getPCA(X_train_allvsall)\n",
    "                mu_allvsall = np.mean(X_train_allvsall,axis=0)\n",
    "                cb_allvsall_dummy_k = np.zeros((T_train_allvsall.shape[0]))\n",
    "                if (model == 0):\n",
    "                    cb_allvsall_dummy_k, cb_test_allvsall_k = train_and_test_bayes(X_train_allvsall,T_train_allvsall,X_test,T_test,digits_allvsall,V_allvsall,mu_allvsall,n)\n",
    "                if (model == 1):\n",
    "                    cb_allvsall_dummy_k, cb_test_allvsall_k = train_and_test_linear(X_train_allvsall,T_train_allvsall,X_test,T_test,digits_allvsall,V_allvsall,mu_allvsall,n)\n",
    "                cb_test_allvsall_arr = np.concatenate((cb_test_allvsall_arr,cb_test_allvsall_k))\n",
    "                k = k+1\n",
    "    \n",
    "    cb_test_allvsall_arr    = np.reshape(cb_test_allvsall_arr,(k,T_test.shape[0]))        \n",
    "    cb_test_allvsall_arr = cb_test_allvsall_arr.T\n",
    "    cb_test_allvsall_digcnt_arr = np.array([])\n",
    "    for d in range(digits.shape[0]):\n",
    "        cb_test_allvsall_digcnt_d  =   np.sum((cb_test_allvsall_arr == d),axis=1)\n",
    "        cb_test_allvsall_digcnt_arr = np.concatenate((cb_test_allvsall_digcnt_arr,cb_test_allvsall_digcnt_d),axis=0)\n",
    "        \n",
    "    cb_test_allvsall_digcnt_arr = np.reshape(cb_test_allvsall_digcnt_arr,(digits.shape[0],T_test.shape[0]))\n",
    "    cb_test_allvsall_digcnt_arr = cb_test_allvsall_digcnt_arr.T\n",
    "    cb_test_allvsall = np.argmax(cb_test_allvsall_digcnt_arr,axis=1)\n",
    "    return cb_allvsall,cb_test_allvsall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collect accuracy as a function of the number of PC for training and testing\n",
    "Find the accuracy of the classifier for `1` to `maxNumPC` principle components. If the results are previously cached, it will load the previous results. Otherwise, it will compute the new results. \n",
    "\n",
    "The accuracy of the training and test data are stored in the files specified by `accName` and `accTestName` respectively. The execution time for training and test  are stored in the file specified by `timeName`.\n",
    " \n",
    "For `maxNumPC = 50`, it tooked about 2 hours to compute on a Intel Core i7-4661 3.5Ghz machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=linear policy=onevsall numPC= 1 myTime= 1.31344008446 myAccurancy= 14.31\n",
      "model=linear policy=allvsall numPC= 1 myTime= 33.2582929134 myAccurancy= 30.07\n",
      "model=bayes policy=onevsall numPC= 1 myTime= 146.331473827 myAccurancy= 15.76\n"
     ]
    }
   ],
   "source": [
    "maxNumPC = 3\n",
    "\n",
    "def apply_classifier(numPC,kesler_switch,model=0):\n",
    "    start = time.time()\n",
    "    if (kesler_switch == 0):\n",
    "        cb, cb_test = train_and_test_onevsall(X,T,X_test,T_test,digits,numPC,model)\n",
    "    else:\n",
    "        cb, cb_test = train_and_test_allvsall(X,T,X_test,T_test,digits,numPC,model)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    myTime = end - start\n",
    "    myAccuracy = get_acc(cb_test , T_test) * 100\n",
    "\n",
    "    return myTime, myAccuracy\n",
    "\n",
    "accName_bayes_onevsall = os.path.join(rDir,'acc_bayes_onevsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "accName_bayes_allvsall = os.path.join(rDir,'acc_bayes_allvsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "timeName_bayes_onevsall = os.path.join(rDir,'time_bayes_onevsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "timeName_bayes_allvsall = os.path.join(rDir,'time_bayes_allvsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "accName_linear_onevsall = os.path.join(rDir,'acc_linear_onevsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "accName_linear_allvsall = os.path.join(rDir,'acc_linear_allvsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "timeName_linear_onevsall = os.path.join(rDir,'time_linear_onevsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "timeName_linear_allvsall = os.path.join(rDir,'time_linear_allvsall_n{}_{}.csv'.format(maxNumPC,rev))\n",
    "    \n",
    "try:\n",
    "    accList_bayes_onevsall = np.loadtxt(accName_bayes_onevsall, ndmin=1, delimiter=',')\n",
    "    accList_bayes_allvsall = np.loadtxt(accName_bayes_allvsall, ndmin=1, delimiter=',')\n",
    "    timeList_bayes_onevsall = np.loadtxt(timeName_bayes_onevsall, ndmin=1, delimiter=',')\n",
    "    timeList_bayes_allvsall = np.loadtxt(timeName_bayes_allvsall, ndmin=1, delimiter=',')\n",
    "    accList_linear_onevsall = np.loadtxt(accName_linear_onevsall, ndmin=1, delimiter=',')\n",
    "    accList_linear_allvsall = np.loadtxt(accName_linear_allvsall, ndmin=1, delimiter=',')\n",
    "    timeList_linear_onevsall = np.loadtxt(timeName_linear_onevsall, ndmin=1, delimiter=',')\n",
    "    timeList_linear_allvsall = np.loadtxt(timeName_linear_allvsall, ndmin=1, delimiter=',')\n",
    "    print 'Imported {}'.format(accName_bayes_onevsall)\n",
    "    print 'Imported {}'.format(accName_bayes_allvsall)\n",
    "    print 'Imported {}'.format(accName_linear_onevsall)\n",
    "    print 'Imported {}'.format(accName_linear_allvsall)\n",
    "    print 'Imported {}'.format(timeName_bayes_onevsall,rev)\n",
    "    print 'Imported {}'.format(timeName_bayes_allvsall,rev)\n",
    "    print 'Imported {}'.format(timeName_linear_onevsall,rev)\n",
    "    print 'Imported {}'.format(timeName_linear_allvsall,rev)\n",
    "    print \"accList_bayes_onevsall.shape =\", accList_bayes_onevsall.shape\n",
    "    print \"accList_bayes_allvsall.shape =\", accList_bayes_allvsall.shape\n",
    "    print \"timeList_bayes_onevsall.shape =\", timeList_bayes_onevsall.shape\n",
    "    print \"timeList_bayes_allvsall.shape =\", timeList_bayes_allvsall.shape\n",
    "    print \"accList_linear_onevsall.shape =\", accList_linear_onevsall.shape\n",
    "    print \"accList_linear_allvsall.shape =\", accList_linear_allvsall.shape\n",
    "    print \"timeList_linear_onevsall.shape =\", timeList_linear_onevsall.shape\n",
    "    print \"timeList_linear_allvsall.shape =\", timeList_linear_allvsall.shape\n",
    "except IOError:\n",
    "    accList_bayes_onevsall = []\n",
    "    accList_bayes_allvsall = []\n",
    "    timeList_bayes_onevsall = []\n",
    "    timeList_bayes_allvsall = []\n",
    "    accList_linear_onevsall = []\n",
    "    accList_linear_allvsall = []\n",
    "    timeList_linear_onevsall = []\n",
    "    timeList_linear_allvsall = []\n",
    "    for n in range(1,maxNumPC+1) :\n",
    "        \n",
    "        myTime, myAccuracy = apply_classifier(numPC=n,kesler_switch=0,model=1)\n",
    "        accList_linear_onevsall.append(myAccuracy)\n",
    "        timeList_linear_onevsall.append(myTime)    \n",
    "        print \"model=linear policy=onevsall numPC=\",n,\"myTime=\",myTime,\"myAccurancy=\",myAccuracy\n",
    "        \n",
    "        myTime, myAccuracy = apply_classifier(numPC=n,kesler_switch=1,model=1)\n",
    "        accList_linear_allvsall.append(myAccuracy)\n",
    "        timeList_linear_allvsall.append(myTime)    \n",
    "        print \"model=linear policy=allvsall numPC=\",n,\"myTime=\",myTime,\"myAccurancy=\",myAccuracy\n",
    "        \n",
    "        myTime, myAccuracy = apply_classifier(numPC=n,kesler_switch=0,model=0)\n",
    "        accList_bayes_onevsall.append(myAccuracy)\n",
    "        timeList_bayes_onevsall.append(myTime)    \n",
    "        print \"model=bayes policy=onevsall numPC=\",n,\"myTime=\",myTime,\"myAccurancy=\",myAccuracy\n",
    "        \n",
    "        myTime, myAccuracy = apply_classifier(numPC=n,kesler_switch=1,model=0)\n",
    "        accList_bayes_allvsall.append(myAccuracy)\n",
    "        timeList_bayes_allvsall.append(myTime)    \n",
    "        print \"model=bayes policy=allvsall numPC=\",n,\"myTime=\",myTime,\"myAccurancy=\",myAccuracy\n",
    "        \n",
    "        \n",
    "        #print \"Time for training with {} PC          = {} seconds\".format(n,myTime)    \n",
    "        #print \"Accuracy for training data with {} PC = {}\".format(n,accuracy_train)\n",
    "        #print \"Accuracy for testing  data with {} PC = {}\".format(n,accuracy_test)\n",
    "        #print\n",
    "\n",
    "    accList_bayes_onevsall = np.array(accList_bayes_onevsall)\n",
    "    accList_bayes_allvsall = np.array(accList_bayes_allvsall)\n",
    "    timeList_bayes_onevsall = np.array(timeList_bayes_onevsall)\n",
    "    timeList_bayes_allvsall = np.array(timeList_bayes_allvsall)\n",
    "    accList_linear_onevsall = np.array(accList_linear_onevsall)\n",
    "    accList_linear_allvsall = np.array(accList_linear_allvsall)\n",
    "    timeList_linear_onevsall = np.array(timeList_linear_onevsall)\n",
    "    timeList_linear_allvsall = np.array(timeList_linear_allvsall)\n",
    "    \n",
    "    np.savetxt(accName_bayes_onevsall, accList_bayes_onevsall, delimiter=',')\n",
    "    np.savetxt(accName_bayes_allvsall, accList_bayes_allvsall, delimiter=',')\n",
    "    np.savetxt(timeName_bayes_onevsall, timeList_bayes_onevsall, delimiter=',')\n",
    "    np.savetxt(timeName_bayes_allvsall, timeList_bayes_allvsall, delimiter=',')\n",
    "    np.savetxt(accName_linear_onevsall, accList_linear_onevsall, delimiter=',')\n",
    "    np.savetxt(accName_linear_allvsall, accList_linear_allvsall, delimiter=',')\n",
    "    np.savetxt(timeName_linear_onevsall, timeList_linear_onevsall, delimiter=',')\n",
    "    np.savetxt(timeName_linear_allvsall, timeList_linear_allvsall, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "m = len(accList_bayes_onevsall)+1\n",
    "nPC = range(1,m)\n",
    "plt.plot(nPC,accList_bayes_onevsall,label=\"accList_bayes_onevsall\")\n",
    "plt.plot(nPC,accList_bayes_allvsall,label=\"accList_bayes_allvsall\")\n",
    "plt.plot(nPC,accList_linear_onevsall,label=\"accList_linear_onevsall\")\n",
    "plt.plot(nPC,accList_linear_allvsall,label=\"accList_linear_allvsall\")\n",
    "plt.ylabel(\"Accuracy in %\")\n",
    "plt.xlabel(\"Number of Principle Component\")\n",
    "plt.title(\"Accuracy for different classifiers\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "fig.set_size_inches(8,8)\n",
    "fName = os.path.join(pDir,'accuracy_n{}_{}.png'.format(n,rev))\n",
    "savefig(fName, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "m = len(timeList_bayes_onevsall)+1\n",
    "nPC = range(1,m)\n",
    "plt.plot(nPC,timeList_bayes_onevsall,label=\"timeList_bayes_onevsall\")\n",
    "plt.plot(nPC,timeList_bayes_allvsall,label=\"timeList_bayes_allvsall\")\n",
    "plt.plot(nPC,timeList_linear_onevsall,label=\"timeList_linear_onevsall\")\n",
    "plt.plot(nPC,timeList_linear_allvsall,label=\"timeList_linear_allvsall\")\n",
    "plt.ylabel(\"time in second\")\n",
    "plt.xlabel(\"Number of Principle Component\")\n",
    "plt.title(\"Time for different classifiers\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "fig.set_size_inches(8,8)\n",
    "fName = os.path.join(pDir,'time_n{}_{}.png'.format(n,rev))\n",
    "savefig(fName, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numPC = 2\n",
    "#cb, cb_test = train_and_test(X,T,X_test,T_test,digits,V,mu,numPC)\n",
    "#cb, cb_test = train_and_test_allvsall(X,T,X_test,T_test,digits,numPC)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##CM = get_CM(cb , T, digits)\n",
    "##CM.columns = letters\n",
    "##CM.index = letters\n",
    "##fName = os.path.join(rDir,\"cm_train_n{}_{}.csv\".format(numPC,rev))\n",
    "##CM.to_csv(fName)\n",
    "##CM\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CM_test = get_CM(cb_test , T_test, digits)\n",
    "##CM_test.columns = letters\n",
    "##CM_test.index = letters\n",
    "##fName = os.path.join(rDir,\"cm_test_n{}_{}.csv\".format(numPC,rev))\n",
    "##CM.to_csv(fName)\n",
    "##CM\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##accuracy_train  = get_acc(cb , T) * 100\n",
    "##print \"accuracy for training =\", accuracy_train\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#accuracy_test  = get_acc(cb_test , T_test) * 100\n",
    "#print \"accuracy for testing  =\", accuracy_test\n",
    "#\n",
    "#acc_arr = np.zeros(shape = (digits.shape[0]))\n",
    "#sens_arr = np.zeros(shape = (digits.shape[0]))\n",
    "#spec_arr = np.zeros(shape = (digits.shape[0]))\n",
    "#ppv_arr = np.zeros(shape = (digits.shape[0]))\n",
    "#\n",
    "#for dig_i in range(digits.shape[0]):\n",
    "#    TP = np.sum(CM_test[dig_i][dig_i])\n",
    "#    FN = np.sum(CM_test[dig_i][:]) -TP\n",
    "#    FP = np.sum(CM_test[:][dig_i]) -TP\n",
    "#    TN = np.sum(np.sum(CM_test)) - TP - FN - FP      \n",
    "#    acc_arr[dig_i] = get_accuracy(TP,FN,FP,TN)\n",
    "#    sens_arr[dig_i] = get_sensitivity(TP,FN,FP,TN)\n",
    "#    spec_arr[dig_i] = get_specificity(TP,FN,FP,TN)\n",
    "#    ppv_arr[dig_i] = get_ppv(TP,FN,FP,TN)\n",
    "#    #print \"CM2_\",dig_i,\":\", CM2_arr[dig_i]\n",
    "#\n",
    "#print \"acc_arr\",acc_arr\n",
    "#print \"sens_arr\",sens_arr\n",
    "#print \"spec_arr\",spec_arr\n",
    "#print \"ppv_arr\",ppv_arr\n",
    "#print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
